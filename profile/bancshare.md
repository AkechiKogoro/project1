#### 1 Project Description for Huntington Bancshares Inc.

a. Initial Involvement

I was brought in to lead the transition and enhancement of Huntington Bancshares Inc.’s data infrastructure on Google Cloud Platform (GCP) to leverage advanced data warehousing and real-time data streaming technologies, ensuring that data-driven decision-making processes were optimized and scaled across the organization.

b. Initial State of the App and Production Environment

Upon my arrival, the production environment primarily relied on traditional data warehouses that were not fully integrated with cloud solutions. The existing applications were robust but needed enhancements in scalability and real-time processing capabilities.

c. The App and Its Functionality

The main application was a data analytics platform designed to provide real-time financial insights and reporting. It integrated various data sources from within the bank to deliver tailored financial products and services to customers.

d. End Users

The end users of the app were internal stakeholders, such as financial analysts, risk management teams, and strategic decision-makers within Huntington Bancshares Inc.

e. Specific Implementations

I led the implementation of real-time data streaming using Kafka and Spark, which enabled instant data ingestion and processing. This was crucial for real-time financial decision-making and risk assessment. Additionally, I enhanced the data warehouse solutions on Snowflake, optimizing them for better performance and scalability.

f. Leadership and Coding Time Distribution

Approximately 60% of my time was dedicated to leadership and strategic planning, while the remaining 40% involved hands-on coding and technical oversight.

g. Challenges and Solutions

In the production environment, we faced challenges with data silos and latency issues. I addressed these by integrating Kafka for seamless data streaming and enhancing our use of Snowflake for quicker data retrieval and analysis. Development challenges included ensuring data security and compliance, which we managed through rigorous testing and adherence to best practices.

h. Team Size and Roles

The team consisted of around 20 members, including data engineers, data scientists, and DevOps engineers. My role was to coordinate between these experts to ensure efficient project execution.

i. Management of Production Environment

Day-to-day management involved agile methodologies with two-week sprints, using tools like Jira for task management and Confluence for documentation. Regular code reviews and continuous integration/continuous deployment (CI/CD) were enforced using Jenkins and Git.

j. Testing Environment

We employed a robust Test-Driven Development (TDD) approach. Automated testing frameworks in Jenkins and manual code reviews ensured high-quality code deployment.

k. Scrum Meetings

Weekly scrum meetings included project managers, data scientists, and key stakeholders. Discussions focused on sprint reviews, backlog grooming, and future planning. I facilitated these meetings to ensure clear communication and alignment on project goals.

#### 2 Tangible Contributions to the App and Production Environment

a. Tools and Decision-Making

Used GCP for overall data management, Snowflake for warehousing, and Kafka with Spark for real-time data processing. Decisions were driven by the need for scalability and real-time capability.

b. Architecture Awareness

Chose a modular architecture allowing for easy integration and scalability. Trade-offs included higher upfront configuration for scalability benefits later.

c. Layouts Awareness

Focused on backend architecture; however, ensured that any frontend interfaces were user-friendly and met the needs of internal stakeholders by collaborating with UX teams.

d. Gathering Requirements

Regular meetings with stakeholders ensured that the development aligned with business needs and compliance standards.

e. SDLC Adherence

Managed all phases of the SDLC from planning to deployment, ensuring robust process adherence and timely deliveries.

f. QA Strategies

Implemented automated testing and continuous integration using Jenkins, which helped maintain a bug-free production environment.

g. Code Review and Learning

Engaged in thorough code reviews and adopted best practices for coding standards across the team.

#### 3 Technical Failure Example

A significant challenge was a data breach in the Kafka streaming service. It was rectified by implementing enhanced security protocols and access controls. Key learning was the importance of proactive security measures in data management.

#### 4 Project Overview (Summary)
I was hired to overhaul Huntington’s data processing capabilities. Collaborating closely with the team, we enhanced data processing and storage capabilities using GCP, Kafka, and Snowflake. We resolved challenges related to data silos and latency, delivering a robust platform that supports real-time financial decision-making. The deliverables included a scalable data warehouse in Snowflake and a real-time data streaming application using Kafka and Spark.